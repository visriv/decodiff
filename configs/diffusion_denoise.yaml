# config.yaml
device: "cuda"  # or "cpu"
experiment:
  train: True
  validate: True
  analysis: True
  run_id: 26
  project: kol
  plot_file_name: 2d_plot
  freq_plot_file_name: freq_spectrum_plot
  plot_video: True
  stability_file_name: temporal_stability
  spectral_analysis: spec_analysis
  save_plot_video_path: pred_video
  eval_node: eval_node
  start_from_checkpoint: False
  checkpoint_path: '' #'runs/kol/23/model_checkpoint_30.pth'  
  # checkpoint_path: 'runs/kol/21/model_checkpoint_15.pth'  
  # checkpoint_path: 'runs/kol/3/model_checkpoint_88.pth'  
  save_ckpt_every_n_epochs: 5
  val_every_n_epochs: 5

training:
  optim:
    method: "adamw"
    lr: 1.0e-3
    wd: 1.0e-5
    betas: [0.9, 0.999]
    gradient_clip_val: 1.0
    max_epochs: 100
    loss_type: "l2"
    # scheduler
    warmup_percentage: 0.1
    lr_scheduler_mode: "cosine"
    min_lr_ratio: 1.0e-3
    warmup_min_lr_ratio: 0.1
    # old
    finetune_epochs: 40
    finetune_learning_rate: 0.00001  
    epochs: 300
  batch_size: 2



data:
  mode: "Training"
  data_dirs: "../data/kol/results_2.h5"
  total_seq_len: 10
  rollout_total_seq_len: 600
  val_downsample_k: 2  # val_downsample_k * rollout_total_seq_len <= total_len * val_ratio
  train_ratio: 0.8
  val_ratio: 0.15
  crop: 0


model:
  family_name: 'DiffusionDenoise'
  diffusion_steps: 20
  clip_denoised: False
  loss_type: 'l1'
  beta_schedule: 'cosine'
  use_ff: False
  fourier_reg_weight: 0.1
  seq_length: 9
  feature_size: 128
  input_steps: 9
  output_steps: 1
  total_steps: 10
  data_channels: 2
  dim: 128
  time_dim: 256
  unet2_mults: [1]
  twin_tower: False
  #controlNet
  control_connect: False
  #fuse at top
  fusion: False
  fusion_params:
    fusion_strategy: "cross_attention" 
    num_heads: 2
    embed_dim: 20 # (in+out)*data_channels

validation:
  n_val_samples: 1

dataloader:
  num_workers: 2
